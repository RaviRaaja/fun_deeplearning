{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Concatenate\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "(X_train, y_train),(X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#tensorflow (no_of_samples, height, width, channels)\n",
    "#theano (no_of_samples, channels, height, width)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1).astype('float32')\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "print(y_train.shape) #(60000,10)\n",
    "print(y_train[0]) #[0,0,0,0,1,0,0,0,0,0]\n",
    "'''\n",
    "\n",
    "def base_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(4,(3,3), input_shape=(28,28,1),activation='relu' ))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10,activation='softmax'))\n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 26, 26, 4)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 4)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 13, 13, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 676)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                6770      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 6,920\n",
      "Trainable params: 6,920\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = base_model()\n",
    "plot_model(model, to_file='default_CNN.png')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.7506 - acc: 0.7648 - val_loss: 0.3189 - val_acc: 0.9087\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.3247 - acc: 0.9037 - val_loss: 0.2177 - val_acc: 0.9356\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.2443 - acc: 0.9268 - val_loss: 0.1656 - val_acc: 0.9511\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.2059 - acc: 0.9378 - val_loss: 0.1423 - val_acc: 0.9576\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.1875 - acc: 0.9432 - val_loss: 0.1265 - val_acc: 0.9628\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.1714 - acc: 0.9488 - val_loss: 0.1178 - val_acc: 0.9651\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.1638 - acc: 0.9504 - val_loss: 0.1122 - val_acc: 0.9679\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.1578 - acc: 0.9523 - val_loss: 0.1098 - val_acc: 0.9681\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.1500 - acc: 0.9542 - val_loss: 0.1051 - val_acc: 0.9692\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.1457 - acc: 0.9559 - val_loss: 0.0996 - val_acc: 0.9704\n",
      "0.9704\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=10, batch_size=128, verbose=1)\n",
    "print(model.evaluate(X_test,y_test,verbose=2)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def functional_model():\n",
    "    # input layer\n",
    "    visible = Input(shape=(28,28,1))\n",
    "    \n",
    "    conv1 = Conv2D(2, kernel_size=(3,3), activation='relu')(visible)\n",
    "    #pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    #flat1 = Flatten()(pool1)\n",
    "    \n",
    "    conv2 = Conv2D(1, kernel_size=(3,3), activation='relu',trainable=False)(visible)\n",
    "    #pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    #flat2 = Flatten()(pool2)\n",
    "    \n",
    "    conv3 = Conv2D(1,kernel_size=(3,3), activation='relu',trainable=False)(visible)\n",
    "    \n",
    "    merge = concatenate([conv1, conv2,conv3])\n",
    "    \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(merge)\n",
    "    dropout1 = Dropout(0.2)(pool1)\n",
    "    flatten1 = Flatten()(dropout1)\n",
    "    # interpretation layer\n",
    "    hidden1 = Dense(10, activation='relu')(flatten1)\n",
    "    # prediction output\n",
    "    output = Dense(10, activation='sigmoid')(hidden1)\n",
    "    model = Model(inputs=visible, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 26, 26, 2)    20          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 26, 26, 1)    10          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 26, 26, 1)    10          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 26, 26, 4)    0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 13, 13, 4)    0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 13, 13, 4)    0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 676)          0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 10)           6770        flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 10)           110         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 6,920\n",
      "Trainable params: 6,900\n",
      "Non-trainable params: 20\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "custom_model = functional_model()\n",
    "print(custom_model.summary())\n",
    "plot_model(custom_model, to_file='custom_CNN.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights before change:\n",
      "[array([[[[ -3.29269111e-01]],\n",
      "\n",
      "        [[  3.23578060e-01]],\n",
      "\n",
      "        [[ -2.77940005e-01]]],\n",
      "\n",
      "\n",
      "       [[[ -4.28223252e-01]],\n",
      "\n",
      "        [[ -4.92406487e-01]],\n",
      "\n",
      "        [[  2.32425153e-01]]],\n",
      "\n",
      "\n",
      "       [[[  1.44603252e-01]],\n",
      "\n",
      "        [[  5.00469327e-01]],\n",
      "\n",
      "        [[  1.68085098e-04]]]], dtype=float32), array([ 0.], dtype=float32)]\n",
      "[array([[[[ 0.55533087]],\n",
      "\n",
      "        [[ 0.03697348]],\n",
      "\n",
      "        [[-0.40264907]]],\n",
      "\n",
      "\n",
      "       [[[ 0.46966326]],\n",
      "\n",
      "        [[-0.2204718 ]],\n",
      "\n",
      "        [[ 0.21844119]]],\n",
      "\n",
      "\n",
      "       [[[-0.57704937]],\n",
      "\n",
      "        [[-0.05162603]],\n",
      "\n",
      "        [[ 0.49214005]]]], dtype=float32), array([ 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Weights before change:\")\n",
    "print (custom_model.layers[2].get_weights())\n",
    "print (custom_model.layers[3].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting custom weights for layers\n",
    "laplacian = [np.asarray([[[[1]],\n",
    "\n",
    "        [[1 ]],\n",
    "\n",
    "        [[1]]],\n",
    "\n",
    "\n",
    "       [[[1]],\n",
    "\n",
    "        [[-8]],\n",
    "\n",
    "        [[1]]],\n",
    "\n",
    "\n",
    "       [[[1]],\n",
    "\n",
    "        [[1]],\n",
    "\n",
    "        [[1]]]], dtype='float32'), np.asarray([ 0.], dtype='float32')]\n",
    "\n",
    "mean_filter = [np.asarray([[[[.111]],\n",
    "\n",
    "        [[.111 ]],\n",
    "\n",
    "        [[.111]]],\n",
    "\n",
    "\n",
    "       [[[.111]],\n",
    "\n",
    "        [[.111]],\n",
    "\n",
    "        [[.111]]],\n",
    "\n",
    "\n",
    "       [[[.111]],\n",
    "\n",
    "        [[.111]],\n",
    "\n",
    "        [[.111]]]], dtype='float32'), np.asarray([ 0.], dtype='float32')]\n",
    "\n",
    "\n",
    "custom_model.layers[2].set_weights(laplacian)\n",
    "custom_model.layers[3].set_weights(mean_filter)\n",
    "\n",
    "#print (custom_model.layers[2].get_weights())\n",
    "#print (custom_model.layers[3].get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.2731 - acc: 0.9170 - val_loss: 0.2124 - val_acc: 0.9359\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 20s 330us/step - loss: 0.2585 - acc: 0.9214 - val_loss: 0.1983 - val_acc: 0.9439\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 20s 334us/step - loss: 0.2513 - acc: 0.9229 - val_loss: 0.1906 - val_acc: 0.9452\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 20s 334us/step - loss: 0.2364 - acc: 0.9281 - val_loss: 0.1794 - val_acc: 0.9504\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 22s 366us/step - loss: 0.2239 - acc: 0.9312 - val_loss: 0.1675 - val_acc: 0.9507\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 23s 379us/step - loss: 0.2194 - acc: 0.9324 - val_loss: 0.1615 - val_acc: 0.9523\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 23s 389us/step - loss: 0.2089 - acc: 0.9357 - val_loss: 0.1573 - val_acc: 0.9545\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.2014 - acc: 0.9383 - val_loss: 0.1486 - val_acc: 0.9554\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.1947 - acc: 0.9403 - val_loss: 0.1474 - val_acc: 0.9543\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 22s 362us/step - loss: 0.1890 - acc: 0.9407 - val_loss: 0.1434 - val_acc: 0.9563\n",
      "95.63\n"
     ]
    }
   ],
   "source": [
    "custom_model.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n",
    "custom_model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=10, batch_size=128, verbose=1)\n",
    "print(custom_model.evaluate(X_test,y_test,verbose=2)[1]*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
